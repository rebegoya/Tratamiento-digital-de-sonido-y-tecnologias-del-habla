{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 6 Tecnologías del Habla\n",
    "\n",
    "\n",
    "### Rebeca Goya Esteban y Grace Silvana Villacrés\n",
    "\n",
    "update: 28 de noviembre de 2024\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Licencia de Creative Commons\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />Este obra está bajo una <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">licencia de Creative Commons Reconocimiento-NoComercial-CompartirIgual 4.0 Internacional</a>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Clasificadores Máquina\n",
    "\n",
    "En este notebook vamos a aplicar tres técnicas de aprendizaje máquina para resolver un problema de clasificación.\n",
    "\n",
    "**Descripción de los datos**: The iris data sets consists of 3 different types of irises’ (Setosa, Versicolour, and Virginica) petal and sepal length, stored in a 150x4 numpy.ndarray\n",
    "The rows being the samples and the columns being: Sepal Length, Sepal Width, Petal Length and Petal Width.\n",
    "\n",
    "\n",
    "En la siguiente celda se cargan los datos y se realiza una división de los mismos en un conjunto de entrenamiento y un conjunto de test. En *X_train* y *X_test* corresponden a carcterı́sticas de tres clases de flores, en total hay 150\n",
    "ejemplos. En *y_train* y *y_test* se encuentra la información de a qué clase\n",
    "pertenece cada una de las 150 flores (tres posibles clases).\n",
    "\n",
    "**¿Cuántas características se están utilizando para representar/describir a cada una de las flores?**\n",
    "\n",
    "**¿Qué porcentaje de los datos se va a utilizar para el entrenamiento?**\n",
    "\n",
    "**¿Cuántos casos/ejemplos tenemos para entrenar?¿y cuántos para probar el desempeño de los métodos?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#imports\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "#load datasets and split into test and train\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  \n",
    "y = iris.target\n",
    "\n",
    "\n",
    "#split train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.1 Naive Bayes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar el Método de Clasificación de [Naïve Bayes GaussianNB](http://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes), donde hay dos asunciones básicas:\n",
    "\n",
    "* Asunción *naïve* de independencia condicional entre las características para una clase de la variable respuesta dada:\n",
    "\n",
    "$$P(x_1,\\ldots,x_d\\mid y_i) = \\prod_{k = 1}^{d}P(x_k\\mid y_i)$$\n",
    "\n",
    "* La verosimilitud de cada una de las características se asume Gaussiana:\n",
    "\n",
    "$$P(x_i \\mid y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_y}} \\exp\\left(-\\frac{(x_i - \\mu_y)^2}{2\\sigma^2_y}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento\n",
    "\n",
    "A continuación entrenamos el algoritmo, lo que implica calcular los parámetros $\\mu_y$ y $\\sigma_y$.\n",
    "\n",
    "* Utilice los datos de entrenamiento (*X_Train* y *y_Train*) y la función *GaussianNB.fit()* para estimar los parámetros de la pdf gaussiana de cada una de las 3 clases de flores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Creamos el modelo de NB\n",
    "\n",
    "model_NB = GaussianNB()\n",
    "\n",
    "#entrenamos\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Media y desviación estándar para las características de cada clase:\n",
    "\n",
    "print(\"Media de la gaussiana para cada clase:\\n Columnas = Características \\n Filas = Clases\\n\")\n",
    "print(model_NB.theta_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Desviación estándar de la gaussiana para cada clase:\\n Columnas = Características \\n Filas = Clases\\n\")\n",
    "print(model_NB.sigma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "* Clasifique cada ejemplo (flor) de los datos de test (x test iris y y test iris) de acuerdo al esquema de clasificación Naive Bayes. Para ello, utilice *model_NB.predict(X_test)*\n",
    "* Calcule el error de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos las muestras de test, utilizando los valores de la función estimados anteriorment en train\n",
    "\n",
    "y_hat_NB = \n",
    "\n",
    "#Calculamos el accuracy\n",
    "\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.2 Ejemplo KNN con sklearn\n",
    "\n",
    "Vamos a utilizar el método de clasificación KNN https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n",
    "**Pruebe diferentes valores para el parámetro K**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "model_KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "#train the model \n",
    "\n",
    "\n",
    "#predict outputs\n",
    "\n",
    "\n",
    "#accuracy\n",
    "\n",
    "\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.3 redes neuronales\n",
    "\n",
    "Vamos a utilizar el método de clasificación redes neuronales https://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\n",
    "\n",
    "**Pruebe diferentes configuraciones de capas y neuronas ocultas**\n",
    "\n",
    "**Pruebe o modificar otros parámetros de la red neuronal**\n",
    "\n",
    "**Qué información nos da el atributo coefs_**\n",
    "\n",
    "**Dibuje en un papel la red neuronal generada para este ejemplo en el caso de utilizar model_RN = MLPClassifier(hidden_layer_sizes=(4,))**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model_RN =\n",
    "\n",
    "#train the model \n",
    "\n",
    "\n",
    "#predict outputs\n",
    "\n",
    "\n",
    "#accuracy\n",
    "\n",
    "\n",
    "\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
