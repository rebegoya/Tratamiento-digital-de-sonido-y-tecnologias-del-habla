{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 6 Tecnologías del Habla\n",
    "\n",
    "\n",
    "#### Rebeca Goya Esteban y Grace Silvana Villacrés\n",
    "Adaptado de: Introduction to Pattern Recognition  A MATLAB \\textregistered Approach.\n",
    "Sergios Theodoridis, Aggelos Pikrakis, Konstantinos Koutroumbas, Dionisis Cavouras.\n",
    "Elservier 2010.\n",
    "\n",
    "update: 4 de diciembre de 2024\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Licencia de Creative Commons\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />Este obra está bajo una <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">licencia de Creative Commons Reconocimiento-NoComercial-CompartirIgual 4.0 Internacional</a>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Time Warping (DTW) para reconocimiento del habla\n",
    "\n",
    "Nos vamos a centrar en una tarea sencilla de reconocimiento del habla: *reconocimiento de palabras aisladas (RPA)*. \n",
    "Este sistema RPA consiste en un conjunto de **patrones de referencia** y una **medida de distancia**. El reconocimiento de una **palabra de test** (entrada que reconoce el sistema) se consigue encontrando el mejor ajuste entre la palabra de test y cada uno de los patrones de referencia en base a la medida de distancia considerada.\n",
    "\n",
    "Si tenemos dos secuencias se puede utilizar su distancia euclídea para cuantificar su similaridad. Si las secuencias tienen diferente longitud, una forma de poder calcular la distancia entre ellas es permitir comprensiones o extensiones locales (*warping*), este efecto se consigue construyendo el camino óptimo a través de los nodos de una rejilla. La rejilla se construye a partir de las dos secuencias en un espacio bidimensional situando una secuencia en el eje horizontal y otra en el eje vertical. Si colocamos la secuencia de referencia en el eje horizontal, las dimensiones de la rejilla son $JxI$, donde $I$ y $J$ son las longitudes de las secuencias de test y de referencia respectivamente. El tipo y el grado permitido de comprensión/expansión se determina mediante las llamadas restricciones locales. Son muy utilizadas las restricciones Sakoe-Chiba. Básicamente son restricciones para los posibles saltos entre los nodos de la rejilla. \n",
    "\n",
    "Como paso previo para comprender mejor la utilización de DTW para reconocimiento del habla vamos a trabajar con secuencias de números. \n",
    "\n",
    "\n",
    "* Sea $P = [-1,-2,0,2]$ la secuencia patrón de referencia $T = [-1,-2,-2,0,2]$ la secuencia de test. **Obtenga el camino óptimo y su distancia acumulada** adoptando las restricciones locales de Sakoe-Chiba. Utilice para ello la función *dtw* de tds_dtw_utils.py, fíjese en los parámetros de entrada y de salida. \n",
    "* Repita para $T = [-1,-2,-2,-2,-2,0,2]$\n",
    "\n",
    "Como T difiere de P únicamente en términos de repetición de un símbolo, la longitud de la repetición no afecta al distancia acumulada, sólo causa más o menos efecto de compresión en el camino. Análogamente en habla podemos tener la misma palabra pero una vez pronunciada más rápido y otra más despacio. Segmentos verticales u horizontales largos son habituales cuando se emplean las restricciones locales de Sakoe-Chiba. Para evitar que estos segmentos sean indefinidamente largos se pueden utilizar restricciones globales.\n",
    "\n",
    "* Repita para T = [-1,-2,-3,0,2,3], ¿qué diferencia hay en este caso?.\n",
    "\n",
    "\n",
    "También se pueden especificar restricciones de extremos. Para explorar la importancia de estas restricciones, dada la secuencia patrón P = [-8,-4,0,4,0,-4] y la secuencia de test T =[0,-8,-4,0,4,0,-4,0,0]:\n",
    "\n",
    "* Obtenga el camino óptimo y su distancia acumulada adoptando las restricciones locales de Sakoe-Chiba.\n",
    "\n",
    "A pesar de que P y T son prácticamente iguales, sólo difieren en los ceros al principio y al final de T la distancia acumulada no es nula. Esta es una situación común, que haya *basura* cerca de los extremos, para solucionarlo se pueden incluir restricciones de extremos que sirven para poder omitir un determinado número de símbolos al principio y al final de la secuencia de test.\n",
    "\n",
    "* Pruebe a utilizar las restricciones de extremos en el ejemplo anterior con la función *DTWSakoeEndp*, fíjese en los parámetros de entrada de la función y permita omitir hasta dos símbolos tanto al inicio como al final de la secuencia de test.\n",
    "\n",
    "Las restricciones de extremos son muy útiles en reconocimiento del habla porque las palabras de test pueden contener periodos de silencio alrededor de los extremos, mientras que los patrones de referencia almacenados en el sistema no.\n",
    "itemize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tds_dtw_utils import *\n",
    "\n",
    "p = np.array(XXXXXXX) #completar\n",
    "t = np.array(XXXXXXX) #completar\n",
    "\n",
    "\n",
    "#Usar la funcion que corresponda en cada caso, con los parámetros adecuados\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "distance_cost_plot(accumulated_cost,path)\n",
    "path_y = [point[0] for point in path]\n",
    "path_x = [point[1] for point in path]\n",
    "plt.plot(path_x,path_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprima por pantalla el coste o distancia total que devuelve la función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(XXXX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Ahora vamos explorar un sistema simple de reconocimiento de palabras aisladas, el sistema tendrá un vocabulario de 10 palabras: zero,one,two...nine. Se trata de un sistema de reconocimiento de palabras aisladas. Necesitamos por lo tanto 10 patrones de referencia uno por cada palabra que es capaz de reconocer el sistema. Los archivos .wav que vamos a utilizar como patrones de referencia, asi como las grabaciones de las palabras de test se encuentrán en la carpeta **data**. Los patrones de referencia están nombrados como zero.wav, one.wav, etc., y las palabras de test están nombradas como **upatternxy.wav**, donde **x** indica el dígito pronunciado por el locutor e **y** indica el número de repetición.\n",
    "\n",
    "* Pruebe a reproducir algunos de los patrones de referencia y algunos de los patrones de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wf\n",
    "import IPython.display as ipd\n",
    "\n",
    "filename = 'upattern01.wav'# probar a reproducir diferentes audios\n",
    "\n",
    "fs,y = wf.read(XXXX)\n",
    "ipd.Audio(XXXX,rate=XXXX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En una primera etapa, un algoritmo de extracción de características convierte la señal de voz en una secuencia de vectores de características. Para construir este sistema utilizamos dos características: la energía localizada y la tasa de cruces por cero localizada (utilizamos sólo estas dos características por simplicidad).\n",
    "\n",
    "En la función **obtainPatterns.m** se extraen las características de los patrones de referencia. Analice esta función:\n",
    "\n",
    "\n",
    "* ¿Qué recorre el bucle for?¿qué realizan cada una de las instrucciones del bucle?.\n",
    "* Complete el codigo para que la ventana a utilizar sea de 20 ms ¿por qué queremos que tenga ese tamaño?¿Qué tipo de ventana se está utilizando (rectangular, hamming...)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtainPatterns():\n",
    "    \n",
    "    protoFSeq = []\n",
    "    protoNames=['zero.wav','one.wav','two.wav','three.wav','four.wav','five.wav','six.wav','seven.wav'\n",
    "                ,'eight.wav','nine.wav']\n",
    "    for fname in protoNames:\n",
    "        fs, x = wf.read(fname)\n",
    "        winlength = int(np.round(0.02*fs))\n",
    "        w = sig.boxcar(winlength)\n",
    "        winstep = winlength # moving window step. No overlap\n",
    "        e = energia2(x,w)\n",
    "        Zcr = zcr2(x,w)\n",
    "        protoFSeq.append(np.array([e,Zcr]))\n",
    "    \n",
    "    return protoFSeq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ejecute la función: ¿Qué contiene protoFSeq?\n",
    "* ¿En cuantas tramas se ha dividido la señal correspondiente a la palabra five?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tds_dtw_utils import *\n",
    "#import os\n",
    "#os.chdir(\"../\")\n",
    "#os.chdir(\"../data\")\n",
    "protoFSeq = obtainPatterns()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00884464 0.00496068 0.00693634 0.00859507 0.01161954 0.01177709\n",
      "  0.09484706 0.38351677 0.56497021 0.83323996 0.96722299 1.\n",
      "  0.9684636  0.77654624 0.62234641 0.67684542 0.76184426 0.44535067\n",
      "  0.56210184 0.64635446 0.26715668 0.11729989 0.05919492 0.02958694\n",
      "  0.0123176  0.01930388 0.01440097 0.00473375 0.01742102 0.00739272\n",
      "  0.01843175]\n",
      " [0.1        0.159375   0.125      0.125      0.153125   0.121875\n",
      "  0.059375   0.0625     0.08125    0.090625   0.09375    0.0875\n",
      "  0.084375   0.103125   0.096875   0.109375   0.084375   0.075\n",
      "  0.090625   0.075      0.078125   0.053125   0.040625   0.06875\n",
      "  0.084375   0.075      0.0625     0.1125     0.06875    0.08125\n",
      "  0.025     ]]\n"
     ]
    }
   ],
   "source": [
    "print(protoFSeq[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(protoFSeq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine la función **IsoDigitRec.m**\n",
    "\n",
    "\n",
    "* Localice dónde se lee la palabra de test (la palabra a reconocer) y dónde se hace la extración de características de esta palabra.\n",
    "* Localice dónde se utiliza DTW para el reconocimiento de las palabras. ¿Qué recorre el bucle?. **Introduzca los dos primeros parámetros** cuando se llama a la función **DTWSakoeEndp** de forma que el primer parámetro sea el conjunto de vectores de características de cada uno de los patrones de referencia (será uno en cada iteración del bucle) y el segundo parámetro sea el conjunto de vectores de características de la palabra de test (este será el mismo para todas las iteraciones del blucle).  \n",
    "* Ejecute el script para una palabra de test. Una vez calculado el coste o distancia del camino óptimo respecto a cada uno de los patrones de referencia ¿cómo decide el sistema cuál es la palabra de entrada al sistema?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IsoDigitRec(protoFSeq, patt_to_rec = 'upattern01'):\n",
    "\n",
    "    protoNames=['zero.wav','one.wav','two.wav','three.wav','four.wav','five.wav','six.wav','seven.wav'\n",
    "                ,'eight.wav','nine.wav']\n",
    "    #Read audio test: to recognize\n",
    "    fs, test = wf.read(patt_to_rec)\n",
    "    winlength = int(np.round(0.02 * fs)) #use the same values as before\n",
    "    \n",
    "    w = sig.boxcar(winlength)\n",
    "    winstep = winlength # moving window step. No overlap\n",
    "    \n",
    "    #compute features for test audio\n",
    "    e = energia2(test,w)\n",
    "    Zcr = zcr2(test,w)\n",
    "    #Create a vector\n",
    "    Ftest=np.array([e,Zcr])\n",
    "    \n",
    "    tolerance=0.1 #tolerance for remove endpoints\n",
    "    LeftEndConstr= int(np.round(tolerance/winstep)) # left endpoint constraint\n",
    "    RightEndConstr = LeftEndConstr\n",
    "    \n",
    "    matchingcost = []\n",
    "    cost = []\n",
    "    for proto in protoFSeq:\n",
    "       \n",
    "        NodeCost, D, path, cost_a, matching_cost_a = dtw_Endp(proto,Ftest,omit_left=LeftEndConstr,\n",
    "                                                              omit_right=RightEndConstr)# Hay que sustituir a y b\n",
    "        \n",
    "        cost.append(cost_a)\n",
    "        matchingcost.append(matching_cost_a)\n",
    "        \n",
    "        \n",
    "    indexofBest = np.argmin(matchingcost);\n",
    "    print(matchingcost)\n",
    "    print('The unknown pattern has been identified as a \"%s\" \\n'%(protoNames[indexofBest]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ejecute el script para todas las palabras de test. Compruebe si los resultados son correctos para todos los ejemplos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'upattern01'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d6e833cdf5d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#os.chdir(\"./data\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mIsoDigitRec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotoFSeq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatt_to_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'upattern01'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-a38b3fbd7c9c>\u001b[0m in \u001b[0;36mIsoDigitRec\u001b[0;34m(protoFSeq, patt_to_rec)\u001b[0m\n\u001b[1;32m      4\u001b[0m                 ,'eight.wav','nine.wav']\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#Read audio test: to recognize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatt_to_rec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mwinlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.02\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#use the same values as before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/io/wavfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(filename, mmap)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0mmmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'upattern01'"
     ]
    }
   ],
   "source": [
    "#os.chdir(\"../\")\n",
    "#os.chdir(\"./data\")\n",
    "\n",
    "IsoDigitRec(protoFSeq, patt_to_rec = 'upattern01')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bibiliografía**\n",
    "\n",
    "Introduction to Pattern Recognition \n",
    "A MATLAB \\textregistered Approach.\n",
    "Sergios Theodoridis, Aggelos Pikrakis, Konstantinos Koutroumbas, Dionisis Cavouras.\n",
    "Elservier 2010."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
